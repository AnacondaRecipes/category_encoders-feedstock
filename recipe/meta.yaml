{% set name = "category_encoders" %}
{% set version = "2.8.0" %}

package:
  name: {{ name }}
  version: {{ version }}

source:
  url: https://github.com/scikit-learn-contrib/{{ name }}/archive/refs/tags/{{ version }}.tar.gz
  sha256: a597827a2337222f6fd18ed92dd9f549e2864a8f14f062526f5ef26f17bfcfd6

build:
  number: 1
  skip: true  # [py<310]
  script: {{ PYTHON }} -m pip install . --no-deps --no-build-isolation -vv

requirements:
  host:
    - python
    - pip
    - poetry-core
  run:
    - python
    - scikit-learn >=1.6.0
    - scipy >=1.0.0
    - pandas >=1.0.5
    - patsy >=0.5.1
    - statsmodels >=0.9.0
    - numpy >=1.14.0

test:
  source_files:
    - tests
  requires:
    - pip
    - pytest
  imports:
    - category_encoders
  commands:
    - pip check
    # test_simple_example fails on win with dtype mismatch - could be specific to the numpy version solved.
    # osx-arm64 fails test_large_samples_binary with FloatingPointError: underflow encountered in cast
    - pytest -vv tests -k "not (test_large_samples_binary or test_simple_example)"

about:
  home: https://github.com/scikit-learn-contrib/category_encoders
  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE.md
  summary: A collection sklearn transformers to encode categorical variables as numeric
  doc_url: https://contrib.scikit-learn.org/category_encoders
  dev_url: https://github.com/scikit-learn-contrib/category_encoders
  description: |-
    A set of scikit-learn-style transformers for encoding categorical variables
    into numeric with different techniques. While ordinal, one-hot, and hashing
    encoders have similar equivalents in the existing scikit-learn version, the
    transformers in this library all share a few useful properties:
    - First-class support for pandas dataframes as an input (and optionally as
      output)
    - Can explicitly configure which columns in the data are encoded by name or
      index, or infer non-numeric columns regardless of input type
    - Can drop any columns with very low variance based on training set
      optionally
    - Portability: train a transformer on data, pickle it, reuse it later and
      get the same thing out.
    - Full compatibility with sklearn pipelines, input an array-like dataset
      like any other transformer

extra:
  recipe-maintainers:
    - bollwyvl
    - nirajd
    - wdm0006
