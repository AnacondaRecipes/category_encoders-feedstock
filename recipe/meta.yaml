{% set name = "category_encoders" %}
{% set version = "1.3.0" %}

package:
  name: {{ name }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: 5dad7fdbadb85dc13af9ea7739b705447e5e19993359d75041913791d8f7f0c1

build:
  number: 0
  skip: true  # [py<38]
  script: {{ PYTHON }} -m pip install . --no-deps --no-build-isolation -vv

requirements:
  host:
    - python
    - pip
    - wheel
    - setuptools
  run:
    - numpy >=1.8.0
    - pandas >=0.16.0
    - patsy >=0.4.0
    - python
    - scikit-learn >=0.15.0
    - scipy >=0.9
    - statsmodels >=0.6.0

test:
  requires:
    - pip
    - pytest
  imports:
    - category_encoders
  commands:
    - pip check

about:
  home: https://github.com/scikit-learn-contrib/category_encoders
  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE.md
  summary: A collection sklearn transformers to encode categorical variables as numeric
  doc_url: https://contrib.scikit-learn.org/category_encoders
  dev_url: https://github.com/scikit-learn-contrib/category_encoders
  description: |-
    A set of scikit-learn-style transformers for encoding categorical variables
    into numeric with different techniques. While ordinal, one-hot, and hashing
    encoders have similar equivalents in the existing scikit-learn version, the
    transformers in this library all share a few useful properties:
    - First-class support for pandas dataframes as an input (and optionally as
      output)
    - Can explicitly configure which columns in the data are encoded by name or
      index, or infer non-numeric columns regardless of input type
    - Can drop any columns with very low variance based on training set
      optionally
    - Portability: train a transformer on data, pickle it, reuse it later and
      get the same thing out.
    - Full compatibility with sklearn pipelines, input an array-like dataset
      like any other transformer

extra:
  recipe-maintainers:
    - bollwyvl
    - nirajd
    - wdm0006
